{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"VGG transcript .ipynb","provenance":[],"collapsed_sections":["thu3upsewIGr","q6vZFcbcjSh7","zSY5a4-KRq9b","M2PURz7Mcf0o","BsQ_pJir-wbW","MrzHJozeHgyx","s_lNDKmiTHND","VOn_GrDabsew","D7j-jA7EIUw7","aXqZ9uX7PdID"],"authorship_tag":"ABX9TyMQvp9rGAz4susCFo51SG3e"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"thu3upsewIGr"},"source":["# 1st Transcription"]},{"cell_type":"code","metadata":{"id":"_8rCSQ2JN7nI"},"source":["import torch\r\n","import torch.nn as nn\r\n","from typing import Union, List, Dict, Any, cast\r\n","\r\n","try:\r\n","    from torch.hub import load_state_dict_from_url\r\n","except ImportError:\r\n","    from torch.utils.model_zoo import load_url as load_state_dict_from_url\r\n","    print(\"Exception Occurred!!\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_rK1I2qgQlIN"},"source":["__all__ = [\r\n","           'VGG', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn',\r\n","           'vgg19_bn', 'vgg_19'\r\n","]\r\n","\r\n","model_urls = {\r\n","    'vgg11': 'https://download.pytorch.org/models/vgg11-bbd30ac9.pth',\r\n","    'vgg13': 'https://download.pytorch.org/models/vgg13-c768596a.pth',\r\n","    'vgg16': 'https://download.pytorch.org/models/vgg16-397923af.pth',\r\n","    'vgg19': 'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth',\r\n","    'vgg11-bn': 'https://download.pytorch.org/models/vgg11_bn-6002323d.pth',\r\n","    'vgg13-bn': 'https://download.pytorch.org/models/vgg13_bn-abd245e5.pth',\r\n","    'vgg16-bn': 'https://dpwnload.pytorch.org/models/vgg16_bn-6c64b313.pth',\r\n","    'vgg19-bn': 'https://download.pytorch.org/models/vgg19_bn-c79401a0.pth',\r\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SECuV11fQmqw"},"source":["class VGG(nn.Module):\r\n","\r\n","    def __init__(\r\n","        self,\r\n","        features: nn.Module,\r\n","        num_classes: int = 1000,\r\n","        init_weights: bool = True\r\n","    ) -> None:\r\n","        super(VGG, self).__init__()\r\n","        self.features = features\r\n","        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\r\n","        self.classifier = nn.Sequential(\r\n","            nn.Linear(512 * 7 * 7, 4096),\r\n","            nn.ReLU(True),\r\n","            nn.Dropout(),\r\n","            nn.Linear(4096, 4096),\r\n","            nn.ReLU(True),\r\n","            nn.Dropout(),\r\n","            nn.Linear(4096, num_classes),\r\n","        )\r\n","        if init_weights:\r\n","            self._initialize_weight()\r\n","\r\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\r\n","        x = self.features(x)\r\n","        x = self.avgpool(x)\r\n","        x = torch.flatten(x, 1)\r\n","        x = self.classifier(x)\r\n","        return x\r\n","\r\n","    def _initialize_weight(self) -> None:\r\n","        for m in self.modules():\r\n","            if isinstance(m, nn.Conv2d):\r\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\r\n","                if m.bias is not None:\r\n","                    nn.init.constant_(m.bias, 0)\r\n","            elif isinstance(m, nn.BatchNorm2d):\r\n","                nn.init.constant_(m.weight, 0, 0.01)\r\n","                nn.init.constant_(m.bias, 0)\r\n","            elif isinstance(m, nn.Linear):\r\n","                nn.init.normal_(m.weight, 0, 0.01)\r\n","                nn.init.constant_(m.bias, 0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bi2wQKebLF0S"},"source":["def make_layers(cfg: List[Union[str, int]], batch_norm: bool = False) -> nn.Sequential:\r\n","    layers: List[nn.Module] = []\r\n","    in_channels = 3\r\n","    for v in cfg:\r\n","        if v == 'M':\r\n","            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\r\n","        else:\r\n","            v = cast(int, v)\r\n","            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\r\n","            if batch_norm:\r\n","                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\r\n","            else:\r\n","                layers += [conv2d, nn.ReLU(inplace=True)]\r\n","            in_channels = v\r\n","    return nn.Sequential(*layers)\r\n","\r\n","\r\n","cfgs: Dict[str, List[Union[str, int]]] = {\r\n","    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\r\n","    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\r\n","    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\r\n","    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\r\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6Ja_MLImZeoL"},"source":["def _vgg(arch: str, \r\n","         cfg: str, \r\n","         batch_norm: bool, \r\n","         pretrained: bool, \r\n","         progress: bool, \r\n","         **kwargs: Any) -> VGG:\r\n","    if pretrained:\r\n","        kwargs['init_weights'] = False\r\n","    model = VGG(make_layers(cfgs[cfg], batch_norm=batch_norm), **kwargs)\r\n","    if pretrained:\r\n","        state_dict = load_state_dict_from_url(model_urls[arch],\r\n","                                              progress=progress)\r\n","        model.load_state_dict(state_dict)\r\n","    return model\r\n","\r\n","def vgg11(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg11', 'A', False, pretrained, progress, **kwargs)\r\n","\r\n","def vgg11_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg11_bn', 'A', True, pretrained, progress, **kwargs)\r\n","\r\n","def vgg13(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg13', 'B', False, pretrained, progress, **kwargs)\r\n","\r\n","def vgg13_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg13_bn', 'B', True, pretrained, progress, **kwargs)\r\n","\r\n","def vgg16(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg16', 'D', False, pretrained, progress, **kwargs)\r\n","\r\n","def vgg16_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg16_bn', 'D', True, pretrained, progress, **kwargs)\r\n","\r\n","def vgg19(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg19', 'E', False, pretrained, progress, **kwargs)\r\n","\r\n","def vgg19_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg19_bn', 'E', True, pretrained, progress, **kwargs)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q6vZFcbcjSh7"},"source":["# 2nd Transcription"]},{"cell_type":"code","metadata":{"id":"nKP2e90Ljcdn"},"source":["import torch\r\n","import torch.nn as nn\r\n","from torch.hub import load_state_dict_from_url\r\n","from typing import Union, List, Dict, Any, cast"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fTrtxtmTHdbs"},"source":["__all__ = [\r\n","           'VGG', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg16', 'vgg16', 'vgg16_bn',\r\n","           'vgg19_bn', 'vgg19',\r\n","]\r\n","\r\n","model_urls = {\r\n","              'vgg11': 'https://download.pytorch.org/models/vgg11-bbd30ac9.pth',\r\n","              'vgg13': 'https://download.pytorch.org/models/vgg13-c768596a.pth',\r\n","              'vgg16': 'https://download.pytorch.org/models/vgg16-397923af.pth',\r\n","              'vgg19': 'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth',\r\n","              'vgg11_bn': 'https://download.pytorch.org/models/vgg11_bn-6002323d.pth',\r\n","              'vgg13_bn': 'https://download.pytorch.org/models/vgg13_bn-abd245e5.pth',\r\n","              'vgg16_bn': 'https://download.pytorch.org/mpdels/vgg16_bn-6c64b313.pth',\r\n","              'vgg19_bn': 'https://download/pytorch.org/models/vgg19_bn-c79401a0.pth',\r\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RepiLjB2JErp"},"source":["class VGG(nn.Module):\r\n","\r\n","    def __init__(\r\n","        self,\r\n","        features: nn.Module,\r\n","        num_classes: int = 1000,\r\n","        init_weights: bool = True,\r\n","    ) -> None:\r\n","        super(VGG, self).__init__()\r\n","        self.features = features,\r\n","        self.avgpool = nn.AdaptivrAvgPool2d((7, 7)),\r\n","        self.classifier = nn.Sequential(\r\n","            nn.Linear(512 * 7 * 7, 4096),\r\n","            nn.ReLU(True),\r\n","            nn.Dropout(),\r\n","            nn.Linear(4096, 4096),\r\n","            nn.ReLU(True),\r\n","            nn.Dropout(),\r\n","            nn.Linear(4096, num_classes),\r\n","        )\r\n","        if init_weights:\r\n","            self._initialize_weights()\r\n","\r\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\r\n","        x = self.features(x)\r\n","        x = self.avgpool(x)\r\n","        x = torch.flatten(x, 1)\r\n","        x = self.classifier(x)\r\n","        return x\r\n","\r\n","    def _initialize_weights(self) -> None:\r\n","        for m in self.modules():\r\n","            if isinstance(m, nn.Conv2d):\r\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearly='relu')\r\n","                if m.bias is not None:\r\n","                    nn.init.constant_(m.bias, 0)\r\n","            elif isinstance(m, nn.BatchNorm2d):\r\n","                nn.init.constant_(m.weight, 1)\r\n","                nn.init.constant_(m.bias, 0)\r\n","            elif isinstance(m, nn.Linear):\r\n","                nn.init.normal_(m.weight, 0, 0.01)\r\n","                nn.init.constant_(m.bias, 0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HYNMWwYqLQps"},"source":["def make_layers(cfg: List[Union[str, int]], batch_norm: bool = False) -> nn.Sequential:\r\n","    layers: List[nn.Module] = []\r\n","    in_channels = 3\r\n","    for v in cfg:\r\n","        if v == 'M':\r\n","            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\r\n","        else:\r\n","            v = cast(int, v)\r\n","            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\r\n","            if batch_norm:\r\n","                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\r\n","            else:\r\n","                layers += [conv2d, nn.ReLU(inplace=True)]\r\n","            in_channels = v\r\n","    return nn.Sequential(*layers)\r\n","\r\n","cfgs: Dict[str, List[Union[str, int]]] = {\r\n","    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 512],\r\n","    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\r\n","    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512,'M'],\r\n","    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\r\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4VRpGYdyOMMH"},"source":["def _vgg(arch: str, \r\n","         cfg: str,\r\n","         batch_norm: bool,\r\n","         pretrained: bool,\r\n","         progress: bool, \r\n","         **kwargs: Any) -> VGG:\r\n","    if pretrained:\r\n","        kwargs['init_weight'] = False\r\n","    model = VGG(make_layers(cfgs[cfg], batch_norm=batch_norm), **kwargs)\r\n","    if pretrained:\r\n","        state_dict = load_state_dict_from_url(model_urls[arch],\r\n","                                              progress=progress)\r\n","        model.load_state_dict(state_dict)\r\n","    return model\r\n","\r\n","def vgg11(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg11', 'A', False, pretrained, progress, **kwargs)\r\n","\r\n","def vgg11_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg13', 'A', True, pretrained, progress, **kwargs)\r\n","\r\n","def vgg13(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg13', 'B', False, pretrained, progress, **kwargs)\r\n","\r\n","def vgg13_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg13_bn', 'B', True, pretrained, progress, **kwargs)\r\n","\r\n","def vgg16(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg16', 'D', False, pretrained, progress, **kwargs)\r\n","\r\n","def vgg16_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg16_bn', 'D', True, pretrained, progress, **kwargs)\r\n","\r\n","def vgg19(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg19', 'E', False, pretrained, progress, **kwargs)\r\n","\r\n","def vgg19_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg19_bn', 'E', True, pretrained, progress, **kwargs)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zSY5a4-KRq9b"},"source":["# 3rd Transcription"]},{"cell_type":"code","metadata":{"id":"qKXBOw6LRwhJ"},"source":["import torch\r\n","import torch.nn as nn\r\n","from torch.hub import load_state_dict_from_url\r\n","from typing import Union, List, Dict, Any, cast"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sYjEdJEJSHRL"},"source":["__all__ = [\r\n","           'VGG', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn',\r\n","           'vgg19_bn', 'vgg19',\r\n","]\r\n","\r\n","model_urls = {\r\n","    'vgg11': 'https://download.pytorch.org/models/vgg11-bbd30ac9.pth',\r\n","    'vgg13': 'https://download.pytorch.org/models/vgg13-c768596a.pth',\r\n","    'vgg16': 'https://download.pytorch.org/models/vgg16-397923af.pth',\r\n","    'vgg19': 'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth',\r\n","    'vgg11_bn': 'https://download.pytorch.org/models/vgg11_bn-6002323d.pth',\r\n","    'vgg13_bn': 'https://download.pytorch.org/models/vgg13_bn-abd245e5.pth',\r\n","    'vgg16_bn': 'https://download.pytorch.org/models/vgg16_bn-6c64b313.pth',\r\n","    'vgg19_bn': 'https://download.pytorch.org/models/vgg19_bn-c79401a0.pth',\r\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"movPYWNkTdZh"},"source":["class VGG(nn.Module):\r\n","\r\n","    def __init__(\r\n","        self,\r\n","        features: nn.Module,\r\n","        num_classes: int = 1000,\r\n","        init_classes: bool = True\r\n","    ) -> None:\r\n","        super(VGG, self).__init__()\r\n","        self.features = features\r\n","        self.avgpool = nn.AdatptiveAvgPool2d((7, 7))\r\n","        self.classifier = nn.Sequential(\r\n","            nn.Linear(512, * 7 * 7, 4096),\r\n","            nn.ReLU(True),\r\n","            nn.Dropout(),\r\n","            nn.Linear(4096, 4096),\r\n","            nn.ReLU(True),\r\n","            nn.Dropout(),\r\n","            nn.Linear(4096, num_classes),\r\n","        )\r\n","        if init_weights:\r\n","            self._initialize_weights()\r\n","\r\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\r\n","        x = self.features(x)\r\n","        x = self.avgpool(x)\r\n","        x = torch.flatten(x, 1)\r\n","        x = self.classifier(x)\r\n","        return x\r\n","\r\n","    def _initialize_weights(self) -> None:\r\n","        for m in self.modules():\r\n","            if isinstance(m, Conv2d):\r\n","                nn.init.kaiming_normal_(m,weight, mode='fan_out', nonlinearity='relu')\r\n","                if m.bias is not None:\r\n","                    nn.init.constant_(m.bias, 0)\r\n","            elif isinstance(m, nn.BatchNorm2d):\r\n","                nn.init.constant_(m.weight, 1)\r\n","                nn.init.constant_(m.bias, 0)\r\n","            elif isinstance(m, nn.Linear):\r\n","                nn.init.normal_(m.weight, 0, 0.01)\r\n","                nn.init.constant_(m.bias, 0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"36RJUA0CW-Wl"},"source":["def make_layers(cfg: List[Union[str,int]], batch_norm: bool = False) -> nn.Sequential:\r\n","    layers: List[nn.Module] = []\r\n","    in_channels = 3\r\n","    for v in cfg:\r\n","        if v == 'M':\r\n","            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\r\n","        else:\r\n","            v = cast(int, v)\r\n","            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\r\n","            if batch_norm:\r\n","                layers += [conv2d, nn.BatchNorm2d, nn.ReLU(inplace=True)]\r\n","            else:\r\n","                layers += [conv2d, nn.ReLU(inplace=True_)]\r\n","            in_channels = v\r\n","    return nn.Sequential(*layers)\r\n","\r\n","cfgs: Dict[str, List[Union[str, int]]] = {\r\n","    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\r\n","    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\r\n","    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\r\n","    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\r\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wfAy5ht6a1xm"},"source":["def _vgg(arch: str, cfg: str, batch_norm, pretrained: bool, progress: bool, **kwargs: Any) -> VGG:\r\n","    if pretrained:\r\n","        kwargs['init_weights'] = False\r\n","    model = VGG(make_layers(cfgs[cfg], batch_norm=batch_norm), **kwargs)\r\n","    if pretrained:\r\n","        state_dict = load_state_dict_from_url(model_urls[arch],\r\n","                                              progress=progress)\r\n","        model.load_state_dict(state_dict)\r\n","    return model\r\n","\r\n","def vgg11(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg11', 'A', False, pretrained, progress, **kwargs)\r\n","\r\n","def vgg11_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg11_bn', 'A', True, pretrained, progress, **kwargs)\r\n","\r\n","def vgg13(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg13', 'B', False, pretrained, progress, **kwargs)\r\n","\r\n","def vgg13_bn(prertrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg13_bn', 'B', True, pretrained, progress, **kwargs)\r\n","\r\n","def vgg16(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg16', 'D', False, pretrained, progress, **kwargs)\r\n","\r\n","def vgg16_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg16_bn', 'D', True, pretrained, progress, **kwargs)\r\n","\r\n","def vgg19(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg19', 'E', False, pretrained, progress, **kwargs)\r\n","\r\n","def vgg19_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg19_bn', 'E', True, pretrained, progress, **kwargs)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M2PURz7Mcf0o"},"source":["# 4th Transcription"]},{"cell_type":"code","metadata":{"id":"IrU2zDvAdhjj"},"source":["import torch\r\n","import torch.nn as nn\r\n","from torch.hub import load_state_dict_from_url\r\n","from typing import Union, List, Dict, Any, cast"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A3fkcJ2ierbI"},"source":["__all__ = [\r\n","           'VGG', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn',\r\n","           'vgg19', 'vgg19_bn',\r\n","]\r\n","\r\n","model_urls = {\r\n","    'vgg11': 'https://download.pytorch.org/models/vgg11-bbd30ac9.pth',\r\n","    'vgg13': 'https://download.pytorch.org/models/vgg13-c768596a.pth',\r\n","    'vgg16': 'https://download.pytorch.org/models/vgg16-397923af.pth',\r\n","    'vgg19': 'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth',\r\n","    'vgg11_bn': 'https://download.pytroch.org/models/vgg11_bn-6002323d.pth',\r\n","    'vgg13_bn': 'https://download.pytorch.org/models/vgg13_bn-abd245e5.pth',\r\n","    'vgg16_bn': 'https://download.pytorch.org/models/vgg16_bn-6c64b313.pth',\r\n","    'vgg19_bn': 'https://download.pytorch.org/models/vgg19_bn-c79401a0.pth',\r\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"65MsY35tf4J9","executionInfo":{"status":"ok","timestamp":1611332454549,"user_tz":-540,"elapsed":1262,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"}}},"source":["class VGG(nn.Module):\r\n","\r\n","    def __init__(\r\n","        self,\r\n","        features: nn.Module,\r\n","        num_classes: int = 1000,\r\n","        init_weights: bool = True\r\n","    ) -> None:\r\n","        super(VGG, self).__init__()\r\n","        self.features = features\r\n","        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\r\n","        self.classifier = nn.Sequential(\r\n","            nn.Linear(512 * 7 * 7, 4096),\r\n","            nn.ReLU(True),\r\n","            nn.Linear(4096, 4096),\r\n","            nn.ReLU(True),\r\n","            nn.Dropout(),\r\n","            nn.Linear(4096, num_classes),\r\n","        )\r\n","        if init_weights:\r\n","            self._initialize_weights()\r\n","\r\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\r\n","        x = self.features(x)\r\n","        x = self.avgpool(x)\r\n","        x = torch.flatten(x, 1)\r\n","        x = self.classifier(x)\r\n","        return x\r\n","\r\n","    def _initialize_weights(self) -> None:\r\n","        for m in self.modules():\r\n","            if isinstance(m, nn.Conv2d):\r\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\r\n","                if m.bias is not None:\r\n","                    nn.init.constant_(m.bias, 0)\r\n","            elif isinstance(m, nn.BatchNorm2d):\r\n","                nn.init.constant_(m.weight, 1)\r\n","                nn.init.constant_(m.bias, 0)\r\n","            elif isinstance(m, nn.Linear):\r\n","                nn.init.normal_(m.weight, 0, 0.01)\r\n","                nn.init.constant_(m.bias, 0)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"bJ7Vyw-M5gMv","executionInfo":{"status":"ok","timestamp":1611332867426,"user_tz":-540,"elapsed":1252,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"}}},"source":["def make_layers(cfg: List[Union[str, int]], batch_norm: bool = False) -> nn.Sequential:\r\n","    layers: List[nn.Module] = []\r\n","    in_channels = 3\r\n","    for v in cfg:\r\n","        if v == 'M':\r\n","            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\r\n","        else:\r\n","            v = cast(int, v)\r\n","            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\r\n","            if batch_norm:\r\n","                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\r\n","            else:\r\n","                layers += [conv2d, nn.ReLU(inplace=True)]\r\n","            in_channels = v\r\n","    return nn.Sequential(*layers)\r\n","\r\n","cfgs: Dict[str, List[Union[str, int]]] = {\r\n","    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\r\n","    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\r\n","    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\r\n","    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\r\n","}"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wllm5ai97Dvh","executionInfo":{"status":"ok","timestamp":1611333843861,"user_tz":-540,"elapsed":1061,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"}}},"source":["def _vgg(arch: str, cfg: str, batch_norm: bool, pretrained: bool, progress: bool, **kwargs: Any) -> VGG:\r\n","    if pretrained:\r\n","        kwargs['init_weights'] = False\r\n","    model = VGG(make_layers(cfgs[cfg], batch_norm=batch_norm), **kwargs)\r\n","    if pretrained:\r\n","        state_dict = load_state_dict_from_url(model_urls[arch],\r\n","                                              progress=progress)\r\n","        model.load_state_dict(state_dict)\r\n","    return model\r\n","\r\n","def vgg11(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg11', 'A', False, pretrained, progress, **kwargs)\r\n","\r\n","def vgg11_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg11_bn', 'A', True, pretrained, progress, **kwargs)\r\n","\r\n","def vgg13(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg13', 'B', False, pretrained, progress, **kwargs)\r\n","\r\n","def vgg13_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg13_bn', 'B', True, pretrained, progress, **kwargs)\r\n","\r\n","def vgg16(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg16', 'D', False, pretrained, progress, **kwargs)\r\n","\r\n","def vgg16_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg16_bn', 'D', True, pretrained, progress, **kwargs)\r\n","\r\n","def vgg19(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg19', 'E', False, pretrained, progress, **kwargs)\r\n","\r\n","def vgg19_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg19_bn', 'E', True, pretrained, progress, **kwargs)"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BsQ_pJir-wbW"},"source":["#5th Transcription"]},{"cell_type":"code","metadata":{"id":"1tdXjgro-3O-","executionInfo":{"status":"ok","timestamp":1611333917477,"user_tz":-540,"elapsed":1524,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"}}},"source":["import torch\r\n","import torch.nn as nn\r\n","from torch.hub import load_state_dict_from_url\r\n","from typing import Union, List, Dict, Any, cast"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"pIJN_i2v_FTO","executionInfo":{"status":"ok","timestamp":1611334200976,"user_tz":-540,"elapsed":1608,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"}}},"source":["__all__ = [\r\n","           'VGG', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn',\r\n","           'vgg19_bn', 'vgg19',\r\n","]\r\n","\r\n","model_urls = {\r\n","    'vgg11': 'https://download.pytorch.org/models/vgg11-bbd30ac9.pth',\r\n","    'vgg13': 'https://download.pytorch.org/models/vgg13-c768596a/pth',\r\n","    'vgg16': 'https://download.pytorch.org/models/vgg16-397923af.pth',\r\n","    'vgg19': 'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth',\r\n","    'vgg11_bn': 'https://download.pytorch.org/models/vgg11_bn-6002323d.pth',\r\n","    'vgg13_bn': 'https://download.pytorch.org/models/vgg13_bn-abd245e5.pth',\r\n","    'vgg16_bn': 'https://download.pytorch.org/models/vgg16_bn-6c64b313.pth',\r\n","    'vgg19_bn': 'https://download.pytorch.org/models/vgg19_bn-c79401a0.pth',\r\n","}"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"So99bu3HAKdr","executionInfo":{"status":"ok","timestamp":1611334848011,"user_tz":-540,"elapsed":2037,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"}}},"source":["class VGG(nn.Module):\r\n","\r\n","    def __init__(\r\n","        self,\r\n","        features: nn.Module,\r\n","        num_classes: int = 1000,\r\n","        init_weights: bool = True\r\n","    ) -> None:\r\n","        super(VGG, self).__init__()\r\n","        self.features = features\r\n","        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\r\n","        self.classifier = nn.Sequential(\r\n","            nn.Linear(512 * 7 * 7, 4096),\r\n","            nn.ReLU(True),\r\n","            nn.Dropout(),\r\n","            nn.Linear(4096, 4096),\r\n","            nn.ReLU(True),\r\n","            nn.Dropout(),\r\n","            nn.Linear(4096, num_classes),\r\n","        )\r\n","        if init_weights:\r\n","            self._initialize_weights()\r\n","\r\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\r\n","        x = self.features(x)\r\n","        x = self.avgpool(x)\r\n","        x = torch.flatten(x, 1)\r\n","        x = self.classifier(x)\r\n","        return x\r\n","\r\n","    def _initialize_weights(self) -> None:\r\n","        for m in self.modules():\r\n","            if isinstance(m, nn.Conv2d):\r\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\r\n","                if m.bias is not None:\r\n","                    nn.init.constant_(m.bias, 0)\r\n","                elif isinstance(m, nn.BatchNorm2d):\r\n","                    nn.init.constant_(m.weight, 1)\r\n","                    nn.init.constant_(m.bias, 0)\r\n","                elif isinstance(m, nn.Linear):\r\n","                    nn.init.normal_(m.weight, 0, 0.01)\r\n","                    nn.init.constant_(m.bias, 0) "],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"qp_BISKhCoUn","executionInfo":{"status":"ok","timestamp":1611335259285,"user_tz":-540,"elapsed":2574,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"}}},"source":["def make_layers(cfg: List[Union[str, int]], batch_norm: bool = False) -> nn.Sequential:\r\n","    layers: List[nn.Module] = []\r\n","    in_channels = 3\r\n","    for v in cfg:\r\n","        if v == 'M':\r\n","            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\r\n","        else:\r\n","            v = cast(int, v)\r\n","            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\r\n","            if batch_norm:\r\n","                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\r\n","            else:\r\n","                layers += [conv2d, nn.ReLU(inplace=True)]\r\n","            in_channels = v\r\n","    return nn.Sequential(*layers)\r\n","\r\n","cfgs: Dict[str, List[Union[str, int]]] = {\r\n","    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\r\n","    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\r\n","    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\r\n","    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M']\r\n","}"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"_S_vhM0DEMnD","executionInfo":{"status":"ok","timestamp":1611336127697,"user_tz":-540,"elapsed":1926,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"}}},"source":["def _vgg(arch: str, cfg: str, batch_norm: bool, pretrained: bool, progress: bool, **kwargs: Any) -> VGG:\r\n","    if pretrained:\r\n","        kwargs['init_weights'] = False\r\n","    model = VGG(make_layers(cfgs[cfg], batch_norm=batch_norm), **kwargs)\r\n","    if pretrained:\r\n","        state_dict = load_state_dict_from_url(model_urls[arch],\r\n","                                              progress=progress)\r\n","        model.load_state_dict(state_dict)\r\n","    return model\r\n","\r\n","def vgg11(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg11', 'A', False, pretrained, progress, **kwargs)\r\n","\r\n","def vgg11_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg11_bn', 'A', True, pretrained, progress, **kwargs)\r\n","\r\n","def vgg13(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg13', 'B', False, pretrained, progress, **kwargs)\r\n","\r\n","def vgg13_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg13_bn', 'B', True, pretrained, progress, **kwargs)\r\n","\r\n","def vgg16(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg16', 'D', False, pretrained, progress, **kwargs)\r\n","\r\n","def vgg16_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg16_bn', 'D', True, pretrained, progress, **kwargs)\r\n","\r\n","def vgg19(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg19', 'E', False, pretrained, progress, **kwargs)\r\n","\r\n","def vgg19_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg19_bn', 'E', True, pretrained, progress, **kwargs)"],"execution_count":27,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MrzHJozeHgyx"},"source":["# 6th Transcription"]},{"cell_type":"code","metadata":{"id":"3uG05fJZJ2V-","executionInfo":{"status":"ok","timestamp":1611336824067,"user_tz":-540,"elapsed":1379,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"}}},"source":["import torch\r\n","import torch.nn as nn\r\n","from torch.hub import load_state_dict_from_url\r\n","from typing import Union, List, Dict, Any, cast"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"ch2XwmeDKKvG","executionInfo":{"status":"ok","timestamp":1611337116965,"user_tz":-540,"elapsed":1780,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"}}},"source":["__all__ = [\r\n","           'VGG', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn',\r\n","           'vgg19', 'vgg19_bn',\r\n","]\r\n","\r\n","model_urls = {\r\n","    'vgg11': 'https://download.pytorch.org/models/vgg11-bbd30ac9.pth',\r\n","    'vgg13': 'https://download.pytroch.org/models/vgg13-c768596a.pth',\r\n","    'vgg16': 'https://download.pytorch.org/models/vgg16-397923af.pth',\r\n","    'vgg19': 'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth',\r\n","    'vgg11_bn': 'https://download.pytorch.org/models/vgg11_bn-6002323d.pth',\r\n","    'vgg13_bn': 'https://download.pytorch.org/models/vgg13_bn-abd245e5.pth',\r\n","    'vgg16_bn': 'https://download.pytorch.org/models/vgg16_bn-6c64b313.pth',\r\n","    'vgg19_bn': 'https://download.pytorch.org/models/vgg19_bn-c79401a0.pth',\r\n","}"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"TwHfQNSYLSVD","executionInfo":{"status":"ok","timestamp":1611337671648,"user_tz":-540,"elapsed":1280,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"}}},"source":["class VGG(nn.Module):\r\n","    \r\n","    def __init__(\r\n","        self,\r\n","        features: nn.Module,\r\n","        num_classes: int = 1000,\r\n","        init_weights: bool = True\r\n","    ) -> None:\r\n","        super(VGG, self).__init__()\r\n","        self.features = features\r\n","        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\r\n","        self.classifier = nn.Sequential(\r\n","            nn.Linear(512 * 7 * 7, 4096),\r\n","            nn.ReLU(True),\r\n","            nn.Dropout(),\r\n","            nn.Linear(4096, 4096),\r\n","            nn.ReLU(True),\r\n","            nn.Dropout(),\r\n","            nn.Linear(4096, num_classes),\r\n","        )\r\n","        if init_weights:\r\n","            self._initialize_weights()\r\n","\r\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\r\n","        x = self.features(x)\r\n","        x = self.avgpool(x)\r\n","        x = torch.flatten(x, 1)\r\n","        x = self.classifier(x)\r\n","        return x\r\n","\r\n","    def _initialize_weights(self) -> None:\r\n","        for m in self.modules():\r\n","            if isinstance(m, nn.Conv2d):\r\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\r\n","                if m.bias is not None:\r\n","                    nn.init.constant_(m.bias, 0)\r\n","            elif isinstance(m, nn.BatchNorm2d):\r\n","                nn.init.constant_(m.weight, 1)\r\n","                nn.init.constant_(m.bias, 0)\r\n","            elif isinstance(m, nn.Linear):\r\n","                nn.init.normal_(m.weight, 0, 0.01)\r\n","                nn.init.constant_(m.bias, 0)"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"jOZyg_XGNXzM","executionInfo":{"status":"ok","timestamp":1611338262960,"user_tz":-540,"elapsed":1018,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"}}},"source":["def make_layers(cfg: List[Union[str, int]], batch_norm: bool = False) -> nn.Sequential:\r\n","    layers: List[nn.Module] = []\r\n","    in_channels = 3\r\n","    for v in cfg:\r\n","        if v == 'M':\r\n","            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\r\n","        else:\r\n","            v = cast(int, v)\r\n","            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\r\n","            if batch_norm:\r\n","                layers += [conv2d, nn.BatchNorm2(v), nn.ReLU(inplace=True)]\r\n","            else:\r\n","                layers += [conv2d, nn.ReLU(inplace=True)]\r\n","            in_channels = v\r\n","        return nn.Sequential(*layers)\r\n","\r\n","cfgs: Dict[str, List[Union[str, int]]] = {\r\n","    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\r\n","    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\r\n","    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\r\n","    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\r\n","}"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"mjLmeAtJPnmx","executionInfo":{"status":"ok","timestamp":1611339196359,"user_tz":-540,"elapsed":1224,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"}}},"source":["def _vgg(arch: str, cfg: str, batch_norm: bool, pretrained: bool, progress: bool, **kwargs: Any) -> VGG:\r\n","    if pretrained:\r\n","        kwargs['init_weights'] = False\r\n","    model = VGG(make_layers(cfgs[cfg], batch_norm=batch_norm), **kwargs)\r\n","    if pretrained:\r\n","        state_dict = load_state_dict_from_url(model_urls[arch],\r\n","                                              progress=progress)\r\n","        model.load_state_dict(state_dict)\r\n","    return model\r\n","\r\n","def vgg11(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg11', 'A', False, pretrained, progress, **kwargs)\r\n","\r\n","def vgg11_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg11_bn', 'A', True, pretrained, progress, **kwargs)\r\n","\r\n","def vgg13(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg13', 'B', False, pretrained, progress, **kwargs)\r\n","\r\n","def vgg13_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg13_bn', 'B', True, pretrained, progress, **kwargs)\r\n","\r\n","def vgg16(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg16', 'D', False, pretrained, progress, **kwargs)\r\n","\r\n","def vgg16_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg16_bn', 'D', True, pretrained, progress, **kwargs)\r\n","\r\n","def vgg19(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg19', 'E', False, pretrained, progress, **kwargs)\r\n","\r\n","def vgg19_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg19_bn', 'E', True, pretrained, progress, **kwargs)"],"execution_count":36,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s_lNDKmiTHND"},"source":["# 7th Transcription"]},{"cell_type":"code","metadata":{"id":"CZYsczUVTTDq","executionInfo":{"status":"ok","timestamp":1611339630850,"user_tz":-540,"elapsed":1881,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"}}},"source":["import torch\r\n","import torch.nn as nn\r\n","from torch.hub import load_state_dict_from_url\r\n","from typing import Union, List, Dict, Any, cast"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"id":"tzo5lfvxU4E-","executionInfo":{"status":"ok","timestamp":1611339912138,"user_tz":-540,"elapsed":2020,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"}}},"source":["__all__ = [\r\n","           'VGG', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn',\r\n","           'vgg19_bn', 'vgg19',\r\n","]\r\n","\r\n","model_urls = {\r\n","    'vgg11': 'https://download.pytorch.org/models/vgg11-bbd30ac9.pth',\r\n","    'vgg13': 'https://download.pytorch.org/models/vgg13-c768596a.pth',\r\n","    'vgg16': 'https://download.pytorch.org/models/vgg16-397923af.pth',\r\n","    'vgg19': 'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth',\r\n","    'vgg11_bn': 'https://download.pytorch.org/models/vgg11_bn-6002323d.pth',\r\n","    'vgg13_bn': 'https://download.pytorch.org/models/vgg13_bn-abd245e5.pth',\r\n","    'vgg16_bn': 'https://download.pytorch.org/models/vgg16_bn-6c64b313.pth',\r\n","    'vgg19_bn': 'https://download.pytorch.org/models/vgg19_bn-c79401a0.pth',\r\n","}"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"id":"_vOTl-SAV8s9","executionInfo":{"status":"ok","timestamp":1611340414213,"user_tz":-540,"elapsed":1405,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"}}},"source":["class VGG(nn.Module):\r\n","\r\n","    def __init__(\r\n","        self,\r\n","        features: nn.Module,\r\n","        num_classes: int = 1000,\r\n","        init_weights: bool = True\r\n","    ) -> None:\r\n","        super(VGG, self).__init__()\r\n","        self.features = features\r\n","        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\r\n","        self.classifier = nn.Sequential(\r\n","            nn.Linear(512 * 7 * 7, 4096),\r\n","            nn.ReLU(True),\r\n","            nn.Dropout(),\r\n","            nn.Linear(4096, 4096),\r\n","            nn.ReLU(True),\r\n","            nn.Dropout(),\r\n","            nn.Linear(4096, num_classes),\r\n","        )\r\n","        if init_weights:\r\n","            self._initialize_weights()\r\n","\r\n","    def forward(self, x:torch.Tensor) -> torch.Tensor:\r\n","        x = self.features(x)\r\n","        x = self.avgpool(x)\r\n","        x = torch.flatten(x, 1)\r\n","        x = self.classifier(x)\r\n","        return x\r\n","\r\n","    def _initialize_weights(self) -> None:\r\n","        for m in self.modules():\r\n","            if isinstance(m, nn.Conv2d):\r\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\r\n","                if m.bias is not None:\r\n","                    nn.init.constant_(m.bias, 0)\r\n","            elif isinstance(m, nn.BatchNorm2d):\r\n","                nn.init.constant(m.weight, 1)\r\n","                nn.init.constant(m.bias, 0)\r\n","            elif isinstance(m, nn.Linear):\r\n","                nn.init.normal_(m.weight, 0, 0.01)\r\n","                nn.init.constant_(m.bias, 0)"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"id":"ionUrfODW0y3","executionInfo":{"status":"ok","timestamp":1611340820756,"user_tz":-540,"elapsed":1708,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"}}},"source":["def make_layers(cfg: List[Union[str, int]], batch_norm: bool = False) -> nn.Sequential:\r\n","    layers: List[nn.Module] = []\r\n","    in_channels = 3\r\n","    for v in cfg:\r\n","        if v == 'M':\r\n","            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\r\n","        else:\r\n","            v = cast(int, v)\r\n","            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\r\n","            if batch_norm:\r\n","                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\r\n","            else:\r\n","                layers += [conv2d, nn.ReLU(inplace=True)]\r\n","            in_channels = v\r\n","    return nn.Sequential(*layers)\r\n","\r\n","cfgs: Dict[str, List[Union[str, int]]] = {\r\n","    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\r\n","    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\r\n","    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\r\n","    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],    \r\n","}"],"execution_count":41,"outputs":[]},{"cell_type":"code","metadata":{"id":"HDCYWDETZalH","executionInfo":{"status":"ok","timestamp":1611341429264,"user_tz":-540,"elapsed":1030,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"}}},"source":["def _vgg(arch: str, cfg: str, batch_norm: bool, pretrained: bool, progress: bool, **kwargs: Any) -> VGG:\r\n","    if pretrained:\r\n","        kwargs['init_weights'] = False\r\n","    model = VGG(make_layers(cfgs[cfg], batch_norm=batch_norm), **kwargs)\r\n","    if pretrained:\r\n","        state_dict = load_state_dict_from_url(model_urls[arch],\r\n","                                              progress=progress)\r\n","        model.load_state_dict(state_dict)\r\n","    return model\r\n","\r\n","def vgg11(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg11', 'A', False, pretrained, progress, **kwargs)\r\n","\r\n","def vgg11_bn(pretraind: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg11_bn', 'A', True, pretrained, progress, **kwargs)\r\n","\r\n","def vgg13(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg13', 'B', False, pretrained, progress, **kwargs)\r\n","\r\n","def vgg13_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg13_bn', 'B', True, pretrained, progress, **kwargs)\r\n","\r\n","def vgg16(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg16', 'D', False, pretrained, progress, **kwargs)\r\n","\r\n","def vgg16_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg16_bn', 'D', True, pretrained, progress, **kwargs)\r\n","\r\n","def vgg19(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg19', 'E', False, pretrained, progress, **kwargs)\r\n","\r\n","def vgg19_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg19_bn', 'E', True, pretrained, progress, **kwargs)"],"execution_count":43,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VOn_GrDabsew"},"source":["# 8th Transcription"]},{"cell_type":"code","metadata":{"id":"FnRuERLwbywK","executionInfo":{"status":"ok","timestamp":1611368027192,"user_tz":-540,"elapsed":737,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"}}},"source":["import torch\r\n","import torch.nn as nn\r\n","from torch.hub import load_state_dict_from_url\r\n","from typing import Union, List, Dict, Any, cast"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"JVp1kpCX_R1L","executionInfo":{"status":"ok","timestamp":1611368027463,"user_tz":-540,"elapsed":675,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"}}},"source":["__all__ = [\r\n","           'VGG', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn',\r\n","           'vgg19_bn', 'vgg19',\r\n","]\r\n","\r\n","model_urls = {\r\n","    'vgg11': 'https://download.pytorch.org/models/vgg11-bbd30ac9.pth',\r\n","    'vgg13': 'https://download.pytorch.org/models/vgg13-c768596a.pth',\r\n","    'vgg16': 'https://download.pytorch.org/models/vgg16-397923af.pth',\r\n","    'vgg19': 'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth',\r\n","    'vgg11_bn': 'https://download.pytorch.org/models/vgg11_bn-6002323d.pth',\r\n","    'vgg13_bn': 'https://download.pytorch.org/models/vgg13_bn-abd245e5.pth',\r\n","    'vgg16_bn': 'https://download.pytorch.org/models/vgg16_bn-6c64b313.pth',\r\n","    'vgg19_bn': 'https://download.pytorch.org/models/vgg19_bn-c79401a0.pth',\r\n","}"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"nZdaIurUAWnc","executionInfo":{"status":"ok","timestamp":1611368281030,"user_tz":-540,"elapsed":729,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"}}},"source":["class VGG(nn.Module):\r\n","\r\n","    def __init__(\r\n","        self,\r\n","        features: nn.Module,\r\n","        num_classes: int = 1000,\r\n","        init_classes: bool = True\r\n","    ) -> None:\r\n","        super(VGG, self).__init__()\r\n","        self.features = features\r\n","        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\r\n","        self.classifier = nn.Sequential(\r\n","            nn.Linear(512 * 7 * 7, 4096),\r\n","            nn.ReLU(True),\r\n","            nn.Dropout(),\r\n","            nn.Linear(4096, 4096),\r\n","            nn.ReLU(True),\r\n","            nn.Dropout(),\r\n","            nn.Linear(4096, num_classes),\r\n","        )\r\n","        if init_weights:\r\n","            self._initialize_weights()\r\n","\r\n","    def forward(self, x:torch.Tensor) -> torch.Tensor:\r\n","        x = self.features(x)\r\n","        x = self.avgpool(x)\r\n","        x = torch.flatten(x, 1)\r\n","        x = self.classifier(x)\r\n","        return x\r\n","\r\n","    def _initialize_weights(self) -> None:\r\n","        for m in self.modules():\r\n","            if isintance(m, nn.Conv2d):\r\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\r\n","                if m.bias is not None:\r\n","                    nn.init.constant_(m.bias, 0)\r\n","            elif isinstance(m, nn.BatchNorm2d):\r\n","                nn.init.constant_(m.weight, 1)\r\n","                nn.init.constant_(m.bias, 0)\r\n","            elif isinstance(m, nn.Linear):\r\n","                nn.init.constant_(m.weight, 0, 0.01)\r\n","                nn.init.constant_(m.bias, 0)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"4uYs5rKHBFLH","executionInfo":{"status":"ok","timestamp":1611369090166,"user_tz":-540,"elapsed":848,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"}}},"source":["def make_layers(cfg: List[Union[str, int]], batch_norm: bool = False) -> nn.Sequential:\r\n","    layers: List[nn.Module] = []\r\n","    in_channels = 3\r\n","    for v in cfg:\r\n","        if v == 'M':\r\n","            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\r\n","        else:\r\n","            v = cast(int, v)\r\n","            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\r\n","            if batch_norm:\r\n","                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\r\n","            else:\r\n","                layers += [conv2d, nn.ReLU(inplace=True)]\r\n","            in_channels = v\r\n","    return nn.Sequential(*layers)\r\n","\r\n","cfgs: Dict[str, List[Union[str, int]]] = {\r\n","    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\r\n","    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\r\n","    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\r\n","    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\r\n","}"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"V_XpyCgXFQjP","executionInfo":{"status":"ok","timestamp":1611369894245,"user_tz":-540,"elapsed":1236,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"}}},"source":["def _vgg(arch: str, cfg: str, batch_norm: bool, pretrained: bool, progress: bool, **kwargs: Any) -> VGG:\r\n","    if pretrained:\r\n","        kwargs['init_weights'] = False\r\n","    model = VGG(make_layers(cfgs[cfg], batch_norm=batch_norm), **kwargs)\r\n","    if pretrained:\r\n","        state_dict = load_state_dict_from_url(model_urls[arch],\r\n","                                              progress=progress)\r\n","        model.load_state_dict(state_dict)\r\n","    return model\r\n","\r\n","def vgg11(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg11', 'A', False, pretrained, progress, **kwargs)\r\n","\r\n","def vgg11_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg11_bn', 'A', True, pretrained, progress, **kwargs)\r\n","\r\n","def vgg13(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg13', 'B', False, pretrained, progress, **kwargs)\r\n","\r\n","def vgg13_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg13_bn', 'B', True, pretrained, progress, **kwargs)\r\n","\r\n","def vgg16(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg16', 'D', False, pretrained, progress, **kwargs)\r\n","\r\n","def vgg16_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg16_bn', 'D', True, pretrained, progress, **kwargs)\r\n","\r\n","def vgg19(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg19', 'E', False, pretrained, progress, **kwargs)\r\n","\r\n","def vgg19_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg19_bn', 'E', True, pretrained, progress, **kwargs)"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D7j-jA7EIUw7"},"source":["# 9th Transcription"]},{"cell_type":"code","metadata":{"id":"ZmUrjTQ0IZXH","executionInfo":{"status":"ok","timestamp":1611370063873,"user_tz":-540,"elapsed":1518,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"}}},"source":["import torch\r\n","import torch.nn as nn\r\n","from torch.hub import load_state_dict_from_url\r\n","from typing import Union, List, Dict, Any, cast"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"XQSQBmZbI-G2","executionInfo":{"status":"ok","timestamp":1611370331704,"user_tz":-540,"elapsed":884,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"}}},"source":["__all__ = [\r\n","           'VGG', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn',\r\n","           'vgg19_bn', 'vgg19',\r\n","]\r\n","\r\n","model_urls = {\r\n","    'vgg11': 'https://download.pytorch.org/models/vgg11-bbd30ac9.pth',\r\n","    'vgg13': 'https://download.pytorch.org/models/vgg13-c768596a.pth',\r\n","    'vgg16': 'https://download.pytorch.org/models/vgg16-397923af.pth',\r\n","    'vgg19': 'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth',\r\n","    'vgg11_bn': 'https://download.pytorch.org/models/vgg11_bn-6002323d.pth',\r\n","    'vgg13_bn': 'https://download.pytorch.org/models/vgg13_bn-abd245e5.pth',\r\n","    'vgg16_bn': 'https://download.pytorch.org/models/vgg16_bn-6c64b313.pth',\r\n","    'vgg19_bn': 'https://download.pytorch.org/models/vgg19_bn-c79401a0.pth',\r\n","}"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"VacitPcAJ_pz","executionInfo":{"status":"ok","timestamp":1611370878905,"user_tz":-540,"elapsed":886,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"}}},"source":["class VGG(nn.Module):\r\n","\r\n","    def __init__(\r\n","        self,\r\n","        features: nn.Module,\r\n","        num_classes: int = 1000,\r\n","        init_weights: bool = True\r\n","    ) -> None:\r\n","        super(VGG, self).__init__()\r\n","        self.features = features\r\n","        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\r\n","        self.classifier = nn.Sequential(\r\n","            nn.Linear(512 * 7 * 7, 4096),\r\n","            nn.ReLU(True),\r\n","            nn.Dropout(),\r\n","            nn.Linear(4096, 4096),\r\n","            nn.ReLU(True),\r\n","            nn.Dropout(),\r\n","            nn.Linear(4096, num_classes),\r\n","        )\r\n","        if init_weights:\r\n","            self._initialize_weights()\r\n","\r\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\r\n","        x = self.features(x)\r\n","        x = self.avgpool(x)\r\n","        x = torch.flatten(x, 1)\r\n","        x = self.classifier(x)\r\n","        return x\r\n","\r\n","    def _initialize_weights(self) -> None:\r\n","        for m in self.modules():\r\n","            if isinstance(m, nn.Conv2d):\r\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\r\n","                if m.bias is not None:\r\n","                    nn.init.constant_(m.bias, 0)\r\n","            elif isinstance(m, nn.BatchNorm2d):\r\n","                nn.init.constant_(m.weight, 1)\r\n","                nn.init.constant_(m.bias, 0)\r\n","            elif isinstance(m, nn.Linear):\r\n","                nn.init.normal_(m.weight, 0, 0.01)\r\n","                nn.init.constant_(m.bias, 0)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"xzl7r9wtMFPh","executionInfo":{"status":"ok","timestamp":1611371244974,"user_tz":-540,"elapsed":884,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"}}},"source":["def make_layers(cfg: List[Union[str, int]], batch_norm: bool = False) -> nn.Sequential:\r\n","    layers: List[nn.Module] = []\r\n","    in_channels = 3\r\n","    for v in cfg:\r\n","        if v == 'M':\r\n","            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\r\n","        else:\r\n","            v = cast(int, v)\r\n","            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\r\n","            if batch_norm:\r\n","                layers += [conv2d, nn.ReLU(inplace=True)]\r\n","            in_channels = v\r\n","    return nn.Sequential(*layers)\r\n","\r\n","cfgs: Dict[str, List[Union[str, int]]] = {\r\n","    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\r\n","    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\r\n","    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\r\n","    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\r\n","}"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"PW9KxQyFNend","executionInfo":{"status":"ok","timestamp":1611371763258,"user_tz":-540,"elapsed":992,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"}}},"source":["def _vgg(arch: str, cfg: str, batch_norm: bool, pretrained: bool, progress: bool, **kwargs: Any) -> VGG:\r\n","    if pretrained:\r\n","        kwargs['init_weights'] = False\r\n","    model = VGG(make_layers(cfgs[cfg], batch_norm=batch_norm), **kwargs)\r\n","    if pretrained:\r\n","        state_dict = load_state_dict_from_url(model_urls[arch],\r\n","                                              progress=progress)\r\n","        model.load_state_dict(state_dict)\r\n","    return model_urls\r\n","\r\n","def vgg11(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg11', 'A', False, pretrained, progress, **kwargs)\r\n","\r\n","def vgg11_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg11_bn', 'A', True, pretrained, progress, **kwargs)\r\n","\r\n","def vgg13(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg13', 'B', False, pretrained, progress, **kwargs)\r\n","\r\n","def vgg13_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg13_bn', 'B', True, pretrained, progress, **kwargs)\r\n","\r\n","def vgg16(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg16', 'D', False, pretrained, progress, **kwargs)\r\n","\r\n","def vgg16_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg16_bn', 'D', True, pretrained, progress, **kwargs)\r\n","\r\n","def vgg19(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg19', 'E', False, pretrained, progress, **kwargs)\r\n","\r\n","def vgg19_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg19_bn', 'E', True, pretrained, progress, **kwargs)"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aXqZ9uX7PdID"},"source":["# 10th Transcription"]},{"cell_type":"code","metadata":{"id":"Fzj6I8lgPf-W","executionInfo":{"status":"ok","timestamp":1611371831876,"user_tz":-540,"elapsed":860,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"}}},"source":["import torch\r\n","import torch.nn as nn\r\n","from torch.hub import load_state_dict_from_url\r\n","from typing import Union, List, Dict, Any, cast"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"_bQTU5OXPt60","executionInfo":{"status":"ok","timestamp":1611372081839,"user_tz":-540,"elapsed":866,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"}}},"source":["__all__ = [\r\n","           'VGG', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn',\r\n","           'vgg19_bn', 'vgg19'\r\n","]\r\n","\r\n","model_urls = {\r\n","    'vgg11': 'https://download.pytorch.org/models/vgg11-bbd30ac9.pth',\r\n","    'vgg13': 'https://download.pytorch.org/models/vgg13-c768596a.pth',\r\n","    'vgg16': 'https://download.pytorch.org/models/vgg16-397923af.pth',\r\n","    'vgg19': 'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth',\r\n","    'vgg11_bn': 'https://download.pytorch.org/models/vgg11_bn-6002323d.pth',\r\n","    'vgg13_bn': 'https://download.pytorch.org/models/vgg13_bn-abd245e5.pth',\r\n","    'vgg16_bn': 'https://download.pytorch.org/models/vgg16_bn-6c64b313.pth',\r\n","    'vgg19_bn': 'https://download.pytorch.org/models/vgg19_bn-c79401a0.pth',\r\n","}"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"8NSMy4A2Qq7u","executionInfo":{"status":"ok","timestamp":1611372476460,"user_tz":-540,"elapsed":659,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"}}},"source":["class VGG(nn.Module):\r\n","\r\n","    def __init__(\r\n","        self,\r\n","        features: nn.Module,\r\n","        num_classes: int = 1000,\r\n","        init_weigths: bool = True\r\n","    ) -> None:\r\n","        super(VGG, self).__init__()\r\n","        self.features = features\r\n","        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\r\n","        self.classifier = nn.Sequential(\r\n","            nn.Linear(512 * 7 * 7, 4096),\r\n","            nn.ReLU(True),\r\n","            nn.Dropout(),\r\n","            nn.Linear(4096, 4096),\r\n","            nn.ReLU(True),\r\n","            nn.Dropout(),\r\n","            nn.Linear(4096, num_classes),\r\n","        )\r\n","        if init_weights:\r\n","            self._initialize_weights()\r\n","\r\n","    def forward(self, x:torch.Tensor) -> torch.Tensor:\r\n","        x = self.features(x)\r\n","        x = self.avgpool(x)\r\n","        x = torch.flatten(x, 1)\r\n","        x = self.classifier(x)\r\n","        return x\r\n","\r\n","    def _initialize_weights(self) -> None:\r\n","        for m in self.modules():\r\n","            if isinstance(m, nn.Conv2d):\r\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\r\n","                if m.bias is not None:\r\n","                    nn.init.constant_(m.bias, 0)\r\n","            elif isinstance(m, nn.BatchNorm2d):\r\n","                nn.init.constant_(m.weight, 1)\r\n","                nn.init.constant_(m.bias, 0)\r\n","            elif isinstance(m, nn.Linear):\r\n","                nn.init.normal_(m.weight, 0, 0.01)\r\n","                nn.init.constant_(m.bias, 0)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"X2iDcMgMSJFr","executionInfo":{"status":"ok","timestamp":1611372918581,"user_tz":-540,"elapsed":1353,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"}}},"source":["def make_layers(cfg: List[Union[str, int]], batch_norm: bool = False) -> nn.Sequential:\r\n","    layers: List[nn.Module] = []\r\n","    in_channels = 3\r\n","    for v in cfg:\r\n","        if v == 'M':\r\n","            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\r\n","        else:\r\n","            v = cast(int, v)\r\n","            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\r\n","            if batch_norm:\r\n","                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\r\n","            else:\r\n","                layers += [conv2d, nn.ReLU(inplace=True)]\r\n","            in_channels = v\r\n","    return nn.Sequential(*layers)\r\n","\r\n","cfgs: Dict[str, List[Union[str, int]]] = {\r\n","    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\r\n","    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\r\n","    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\r\n","    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\r\n","}"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"BtqAsL0pT3GR","executionInfo":{"status":"ok","timestamp":1611373434674,"user_tz":-540,"elapsed":985,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"}}},"source":["def _vgg(arch: str, cfg: str, batch_norm: bool, pretrained: bool, progress: bool, **kwargs: Any) -> VGG:\r\n","    if pretrained:\r\n","        kwargs['init_weights'] = False\r\n","    model = VGG(make_layers(cfgs[cfg], batch_norm=batch_norm), **kwargs)\r\n","    if pretrained:\r\n","        state_dict = load_state_dict_from_url(model_urls[arch],\r\n","                                              progress=progress)\r\n","        model.load_state_dict(state_dict)\r\n","    return model\r\n","\r\n","def vgg11(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg11', 'A', False, pretrained, progress, **kwargs)\r\n","\r\n","def vgg11_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg11_bn', 'A', True, pretrained, progress, **kwargs)\r\n","\r\n","def vgg13(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg13', 'B', False, pretrained, progress, **kwargs)\r\n","\r\n","def vgg13_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg13_bn', 'B', True, pretrained, progress, **kwargs)\r\n","\r\n","def vgg16(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg16', 'D', False, pretrained, progress, **kwargs)\r\n","\r\n","def vgg16_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg16_bn', 'D', True, pretrained, progress, **kwargs)\r\n","\r\n","def vgg19(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg19', 'E', False, pretrained, progress, **kwargs)\r\n","\r\n","def vgg19_bn(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> VGG:\r\n","    return _vgg('vgg19_bn', 'E', True, pretrained, progress, **kwargs)"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"GXycqd21V1MD"},"source":[""],"execution_count":null,"outputs":[]}]}