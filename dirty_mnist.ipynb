{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":751,"status":"ok","timestamp":1613226637876,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"},"user_tz":-540},"id":"FG2NXe-iTCSE","outputId":"89e525d0-1e34-44b0-be28-c7710db7b386"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"]}],"source":["from google.colab import drive\r\n","\r\n","drive.mount('/content/gdrive/')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":893,"status":"ok","timestamp":1613226638636,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"},"user_tz":-540},"id":"5v0ZFM9scj0_"},"outputs":[],"source":["import os\r\n","from typing import Tuple, Sequence, Callable\r\n","import csv\r\n","import cv2 # 학교에 없는 코드\r\n","import numpy as np\r\n","import pandas as pd\r\n","from PIL import Image\r\n","from datetime import datetime\r\n","import matplotlib.pyplot as plt\r\n","import torch\r\n","import torch.optim as optim\r\n","from torch import nn, Tensor\r\n","from torch.utils.data import Dataset, DataLoader\r\n","from torchsummary import summary # 학교에 없는 코드\r\n","\r\n","from torchvision import transforms\r\n","from torchvision.models import resnet34, resnet50"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":1335,"status":"ok","timestamp":1613226640344,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"},"user_tz":-540},"id":"sXvSLH46nlND"},"outputs":[],"source":["class MnistDataset(Dataset):\r\n","    def __init__(\r\n","        self,\r\n","        dir: os.PathLike,\r\n","        image_ids: os.PathLike,\r\n","        transforms: Sequence[Callable]\r\n","    ) -\u003e None:\r\n","        self.dir = dir\r\n","        self.transforms = transforms\r\n","\r\n","        self.labels = {}\r\n","\r\n","        try:\r\n","            with open(image_ids, 'r') as f:\r\n","                reader = csv.reader(f)\r\n","                next(reader) # csv 파일 맨 윗줄 생략\r\n","                for row in reader:\r\n","                    self.labels[int(row[0])] = list(map(int, row[1:]))\r\n","        except Exception as err:\r\n","            raise err\r\n","\r\n","        self.image_ids = list(self.labels.keys())\r\n","\r\n","    def __len__(self): # 스페셜 메소드\r\n","        return len(self.image_ids)\r\n","\r\n","    def __getitem__(self, index: int) -\u003e Tuple[Tensor]: # 스페셜 메소드 -\u003e 데이터 레이블과 같이 가져옴\r\n","        image_id = self.image_ids[index]\r\n","        image = Image.open(\r\n","            os.path.join(\r\n","                self.dir, f'{str(image_id).zfill(5)}.png')).convert('RGB')\r\n","        target = np.array(self.labels.get(image_id)).astype(np.float32)\r\n","\r\n","        if self.transforms is not None:\r\n","            image = self.transforms(image)\r\n","\r\n","        return image, target"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":758,"status":"ok","timestamp":1613226642184,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"},"user_tz":-540},"id":"blhXT10juPOU"},"outputs":[],"source":["transforms_train = transforms.Compose([\r\n","    transforms.RandomHorizontalFlip(p=0.5),\r\n","    transforms.RandomVerticalFlip(p=0.5),\r\n","    transforms.ToTensor(),\r\n","    transforms.Normalize(\r\n","        [0.485, 0.456, 0.406],\r\n","        [0.229, 0.224, 0.225]\r\n","    )\r\n","])\r\n","\r\n","transforms_test = transforms.Compose([\r\n","    transforms.ToTensor(),\r\n","    transforms.Normalize(\r\n","        [0.485, 0.456, 0.406],\r\n","        [0.229, 0.224, 0.225]\r\n","    )\r\n","])"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":476,"status":"ok","timestamp":1613226643132,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"},"user_tz":-540},"id":"Qxl14FifXVzS","outputId":"e19d64d0-736d-4440-d35e-eb84d1866d2d"},"outputs":[{"name":"stdout","output_type":"stream","text":["current_dir: /content/gdrive/MyDrive/data/dirty mnist\n"]}],"source":["data_dir = '/content/gdrive/MyDrive/data/dirty mnist/'\r\n","train_dir = os.path.join(data_dir, 'train_dirty_mnist')\r\n","train_label_path = os.path.join(data_dir, 'dirty_mnist_answer.csv')\r\n","test_dir = os.path.join(data_dir, 'test_dirty_mnist')\r\n","test_label_path = os.path.join(data_dir, 'sample_submission.csv')\r\n","\r\n","try:\r\n","    os.chdir(data_dir)\r\n","    print('current_dir:', os.getcwd())\r\n","except Exception as err:\r\n","    print(str(err))"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1151,"status":"ok","timestamp":1613226645359,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"},"user_tz":-540},"id":"SOwmN4fozkKN","outputId":"a3093fcd-5d38-43b4-b6c8-1ef258052ed5"},"outputs":[{"name":"stdout","output_type":"stream","text":["current dir: /content/gdrive/MyDrive/data/dirty mnist\n"]}],"source":["try:\r\n","    print('current dir:', os.getcwd())\r\n","    trainset = MnistDataset('./train_dirty_mnist', './dirty_mnist_answer.csv',\r\n","                            transforms_train) # pixel, label, transform\r\n","    testset = MnistDataset('./test_dirty_mnist', './sample_submission.csv',\r\n","                           transforms_test) # pixel, label, transform\r\n","\r\n","    train_loader = DataLoader(trainset, batch_size=32, num_workers=2)\r\n","    test_loader = DataLoader(testset, batch_size=8, num_workers=1)\r\n","except Exception as err:\r\n","    print(str(err))"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4682,"status":"ok","timestamp":1613226651503,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"},"user_tz":-540},"id":"ozQn-1zDxLMb","outputId":"88195a4d-0998-49c7-dc52-6115daca0c3d"},"outputs":[{"name":"stdout","output_type":"stream","text":["device: cuda\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 128, 128]           9,408\n","       BatchNorm2d-2         [-1, 64, 128, 128]             128\n","              ReLU-3         [-1, 64, 128, 128]               0\n","         MaxPool2d-4           [-1, 64, 64, 64]               0\n","            Conv2d-5           [-1, 64, 64, 64]           4,096\n","       BatchNorm2d-6           [-1, 64, 64, 64]             128\n","              ReLU-7           [-1, 64, 64, 64]               0\n","            Conv2d-8           [-1, 64, 64, 64]          36,864\n","       BatchNorm2d-9           [-1, 64, 64, 64]             128\n","             ReLU-10           [-1, 64, 64, 64]               0\n","           Conv2d-11          [-1, 256, 64, 64]          16,384\n","      BatchNorm2d-12          [-1, 256, 64, 64]             512\n","           Conv2d-13          [-1, 256, 64, 64]          16,384\n","      BatchNorm2d-14          [-1, 256, 64, 64]             512\n","             ReLU-15          [-1, 256, 64, 64]               0\n","       Bottleneck-16          [-1, 256, 64, 64]               0\n","           Conv2d-17           [-1, 64, 64, 64]          16,384\n","      BatchNorm2d-18           [-1, 64, 64, 64]             128\n","             ReLU-19           [-1, 64, 64, 64]               0\n","           Conv2d-20           [-1, 64, 64, 64]          36,864\n","      BatchNorm2d-21           [-1, 64, 64, 64]             128\n","             ReLU-22           [-1, 64, 64, 64]               0\n","           Conv2d-23          [-1, 256, 64, 64]          16,384\n","      BatchNorm2d-24          [-1, 256, 64, 64]             512\n","             ReLU-25          [-1, 256, 64, 64]               0\n","       Bottleneck-26          [-1, 256, 64, 64]               0\n","           Conv2d-27           [-1, 64, 64, 64]          16,384\n","      BatchNorm2d-28           [-1, 64, 64, 64]             128\n","             ReLU-29           [-1, 64, 64, 64]               0\n","           Conv2d-30           [-1, 64, 64, 64]          36,864\n","      BatchNorm2d-31           [-1, 64, 64, 64]             128\n","             ReLU-32           [-1, 64, 64, 64]               0\n","           Conv2d-33          [-1, 256, 64, 64]          16,384\n","      BatchNorm2d-34          [-1, 256, 64, 64]             512\n","             ReLU-35          [-1, 256, 64, 64]               0\n","       Bottleneck-36          [-1, 256, 64, 64]               0\n","           Conv2d-37          [-1, 128, 64, 64]          32,768\n","      BatchNorm2d-38          [-1, 128, 64, 64]             256\n","             ReLU-39          [-1, 128, 64, 64]               0\n","           Conv2d-40          [-1, 128, 32, 32]         147,456\n","      BatchNorm2d-41          [-1, 128, 32, 32]             256\n","             ReLU-42          [-1, 128, 32, 32]               0\n","           Conv2d-43          [-1, 512, 32, 32]          65,536\n","      BatchNorm2d-44          [-1, 512, 32, 32]           1,024\n","           Conv2d-45          [-1, 512, 32, 32]         131,072\n","      BatchNorm2d-46          [-1, 512, 32, 32]           1,024\n","             ReLU-47          [-1, 512, 32, 32]               0\n","       Bottleneck-48          [-1, 512, 32, 32]               0\n","           Conv2d-49          [-1, 128, 32, 32]          65,536\n","      BatchNorm2d-50          [-1, 128, 32, 32]             256\n","             ReLU-51          [-1, 128, 32, 32]               0\n","           Conv2d-52          [-1, 128, 32, 32]         147,456\n","      BatchNorm2d-53          [-1, 128, 32, 32]             256\n","             ReLU-54          [-1, 128, 32, 32]               0\n","           Conv2d-55          [-1, 512, 32, 32]          65,536\n","      BatchNorm2d-56          [-1, 512, 32, 32]           1,024\n","             ReLU-57          [-1, 512, 32, 32]               0\n","       Bottleneck-58          [-1, 512, 32, 32]               0\n","           Conv2d-59          [-1, 128, 32, 32]          65,536\n","      BatchNorm2d-60          [-1, 128, 32, 32]             256\n","             ReLU-61          [-1, 128, 32, 32]               0\n","           Conv2d-62          [-1, 128, 32, 32]         147,456\n","      BatchNorm2d-63          [-1, 128, 32, 32]             256\n","             ReLU-64          [-1, 128, 32, 32]               0\n","           Conv2d-65          [-1, 512, 32, 32]          65,536\n","      BatchNorm2d-66          [-1, 512, 32, 32]           1,024\n","             ReLU-67          [-1, 512, 32, 32]               0\n","       Bottleneck-68          [-1, 512, 32, 32]               0\n","           Conv2d-69          [-1, 128, 32, 32]          65,536\n","      BatchNorm2d-70          [-1, 128, 32, 32]             256\n","             ReLU-71          [-1, 128, 32, 32]               0\n","           Conv2d-72          [-1, 128, 32, 32]         147,456\n","      BatchNorm2d-73          [-1, 128, 32, 32]             256\n","             ReLU-74          [-1, 128, 32, 32]               0\n","           Conv2d-75          [-1, 512, 32, 32]          65,536\n","      BatchNorm2d-76          [-1, 512, 32, 32]           1,024\n","             ReLU-77          [-1, 512, 32, 32]               0\n","       Bottleneck-78          [-1, 512, 32, 32]               0\n","           Conv2d-79          [-1, 256, 32, 32]         131,072\n","      BatchNorm2d-80          [-1, 256, 32, 32]             512\n","             ReLU-81          [-1, 256, 32, 32]               0\n","           Conv2d-82          [-1, 256, 16, 16]         589,824\n","      BatchNorm2d-83          [-1, 256, 16, 16]             512\n","             ReLU-84          [-1, 256, 16, 16]               0\n","           Conv2d-85         [-1, 1024, 16, 16]         262,144\n","      BatchNorm2d-86         [-1, 1024, 16, 16]           2,048\n","           Conv2d-87         [-1, 1024, 16, 16]         524,288\n","      BatchNorm2d-88         [-1, 1024, 16, 16]           2,048\n","             ReLU-89         [-1, 1024, 16, 16]               0\n","       Bottleneck-90         [-1, 1024, 16, 16]               0\n","           Conv2d-91          [-1, 256, 16, 16]         262,144\n","      BatchNorm2d-92          [-1, 256, 16, 16]             512\n","             ReLU-93          [-1, 256, 16, 16]               0\n","           Conv2d-94          [-1, 256, 16, 16]         589,824\n","      BatchNorm2d-95          [-1, 256, 16, 16]             512\n","             ReLU-96          [-1, 256, 16, 16]               0\n","           Conv2d-97         [-1, 1024, 16, 16]         262,144\n","      BatchNorm2d-98         [-1, 1024, 16, 16]           2,048\n","             ReLU-99         [-1, 1024, 16, 16]               0\n","      Bottleneck-100         [-1, 1024, 16, 16]               0\n","          Conv2d-101          [-1, 256, 16, 16]         262,144\n","     BatchNorm2d-102          [-1, 256, 16, 16]             512\n","            ReLU-103          [-1, 256, 16, 16]               0\n","          Conv2d-104          [-1, 256, 16, 16]         589,824\n","     BatchNorm2d-105          [-1, 256, 16, 16]             512\n","            ReLU-106          [-1, 256, 16, 16]               0\n","          Conv2d-107         [-1, 1024, 16, 16]         262,144\n","     BatchNorm2d-108         [-1, 1024, 16, 16]           2,048\n","            ReLU-109         [-1, 1024, 16, 16]               0\n","      Bottleneck-110         [-1, 1024, 16, 16]               0\n","          Conv2d-111          [-1, 256, 16, 16]         262,144\n","     BatchNorm2d-112          [-1, 256, 16, 16]             512\n","            ReLU-113          [-1, 256, 16, 16]               0\n","          Conv2d-114          [-1, 256, 16, 16]         589,824\n","     BatchNorm2d-115          [-1, 256, 16, 16]             512\n","            ReLU-116          [-1, 256, 16, 16]               0\n","          Conv2d-117         [-1, 1024, 16, 16]         262,144\n","     BatchNorm2d-118         [-1, 1024, 16, 16]           2,048\n","            ReLU-119         [-1, 1024, 16, 16]               0\n","      Bottleneck-120         [-1, 1024, 16, 16]               0\n","          Conv2d-121          [-1, 256, 16, 16]         262,144\n","     BatchNorm2d-122          [-1, 256, 16, 16]             512\n","            ReLU-123          [-1, 256, 16, 16]               0\n","          Conv2d-124          [-1, 256, 16, 16]         589,824\n","     BatchNorm2d-125          [-1, 256, 16, 16]             512\n","            ReLU-126          [-1, 256, 16, 16]               0\n","          Conv2d-127         [-1, 1024, 16, 16]         262,144\n","     BatchNorm2d-128         [-1, 1024, 16, 16]           2,048\n","            ReLU-129         [-1, 1024, 16, 16]               0\n","      Bottleneck-130         [-1, 1024, 16, 16]               0\n","          Conv2d-131          [-1, 256, 16, 16]         262,144\n","     BatchNorm2d-132          [-1, 256, 16, 16]             512\n","            ReLU-133          [-1, 256, 16, 16]               0\n","          Conv2d-134          [-1, 256, 16, 16]         589,824\n","     BatchNorm2d-135          [-1, 256, 16, 16]             512\n","            ReLU-136          [-1, 256, 16, 16]               0\n","          Conv2d-137         [-1, 1024, 16, 16]         262,144\n","     BatchNorm2d-138         [-1, 1024, 16, 16]           2,048\n","            ReLU-139         [-1, 1024, 16, 16]               0\n","      Bottleneck-140         [-1, 1024, 16, 16]               0\n","          Conv2d-141          [-1, 512, 16, 16]         524,288\n","     BatchNorm2d-142          [-1, 512, 16, 16]           1,024\n","            ReLU-143          [-1, 512, 16, 16]               0\n","          Conv2d-144            [-1, 512, 8, 8]       2,359,296\n","     BatchNorm2d-145            [-1, 512, 8, 8]           1,024\n","            ReLU-146            [-1, 512, 8, 8]               0\n","          Conv2d-147           [-1, 2048, 8, 8]       1,048,576\n","     BatchNorm2d-148           [-1, 2048, 8, 8]           4,096\n","          Conv2d-149           [-1, 2048, 8, 8]       2,097,152\n","     BatchNorm2d-150           [-1, 2048, 8, 8]           4,096\n","            ReLU-151           [-1, 2048, 8, 8]               0\n","      Bottleneck-152           [-1, 2048, 8, 8]               0\n","          Conv2d-153            [-1, 512, 8, 8]       1,048,576\n","     BatchNorm2d-154            [-1, 512, 8, 8]           1,024\n","            ReLU-155            [-1, 512, 8, 8]               0\n","          Conv2d-156            [-1, 512, 8, 8]       2,359,296\n","     BatchNorm2d-157            [-1, 512, 8, 8]           1,024\n","            ReLU-158            [-1, 512, 8, 8]               0\n","          Conv2d-159           [-1, 2048, 8, 8]       1,048,576\n","     BatchNorm2d-160           [-1, 2048, 8, 8]           4,096\n","            ReLU-161           [-1, 2048, 8, 8]               0\n","      Bottleneck-162           [-1, 2048, 8, 8]               0\n","          Conv2d-163            [-1, 512, 8, 8]       1,048,576\n","     BatchNorm2d-164            [-1, 512, 8, 8]           1,024\n","            ReLU-165            [-1, 512, 8, 8]               0\n","          Conv2d-166            [-1, 512, 8, 8]       2,359,296\n","     BatchNorm2d-167            [-1, 512, 8, 8]           1,024\n","            ReLU-168            [-1, 512, 8, 8]               0\n","          Conv2d-169           [-1, 2048, 8, 8]       1,048,576\n","     BatchNorm2d-170           [-1, 2048, 8, 8]           4,096\n","            ReLU-171           [-1, 2048, 8, 8]               0\n","      Bottleneck-172           [-1, 2048, 8, 8]               0\n","AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n","          Linear-174                 [-1, 1000]       2,049,000\n","          ResNet-175                 [-1, 1000]               0\n","          Linear-176                   [-1, 26]          26,026\n","================================================================\n","Total params: 25,583,058\n","Trainable params: 25,583,058\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.75\n","Forward/backward pass size (MB): 374.28\n","Params size (MB): 97.59\n","Estimated Total Size (MB): 472.62\n","----------------------------------------------------------------\n","None\n"]}],"source":["class Resnet34(nn.Module):\r\n","    def __init__(self) -\u003e None:\r\n","        super.__init__()\r\n","        self.resnet = resnet34(pretrained=True)\r\n","        self.classifier = nn.Linear(1000, 26)\r\n","\r\n","    def forward(self, x):\r\n","        x = self.resnet(x)\r\n","        x = self.classifier(x)\r\n","\r\n","        return x\r\n","\r\n","\r\n","class Resnet50(nn.Module):\r\n","    def __init__(self) -\u003e None:\r\n","        super().__init__()\r\n","        self.resnet = resnet50(pretrained=True)\r\n","        self.classifier = nn.Linear(1000, 26)\r\n","\r\n","    def forward(self, x):\r\n","        x = self.resnet(x)\r\n","        x = self.classifier(x)\r\n","\r\n","        return x\r\n","\r\n","\r\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n","print('device:', device)\r\n","model = Resnet34().to(device)\r\n","print(summary(model, input_size=(3, 256, 256)))"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7150824,"status":"ok","timestamp":1613233804896,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"},"user_tz":-540},"id":"hXTar3u-DMy4","outputId":"79b6292c-b021-4226-b75c-b4aba12b1bb1"},"outputs":[{"name":"stdout","output_type":"stream","text":["======================= start training =======================\n","epoch: 0, step: 155, loss: 0.69822, acc: 0.52163\n","epoch: 0, step: 311, loss: 0.68661, acc: 0.53606\n","epoch: 0, step: 467, loss: 0.68989, acc: 0.56010\n","epoch: 0, step: 623, loss: 0.68627, acc: 0.53365\n","epoch: 0, step: 779, loss: 0.67931, acc: 0.53846\n","epoch: 0, step: 935, loss: 0.67833, acc: 0.54808\n","epoch: 0, step: 1091, loss: 0.67192, acc: 0.57212\n","epoch: 0, step: 1247, loss: 0.67575, acc: 0.54808\n","epoch: 0, step: 1403, loss: 0.67221, acc: 0.55889\n","epoch: 0, step: 1559, loss: 0.67410, acc: 0.54688\n","epoch: 1, step: 155, loss: 0.66548, acc: 0.54567\n","epoch: 1, step: 311, loss: 0.66395, acc: 0.57812\n","epoch: 1, step: 467, loss: 0.62714, acc: 0.60096\n","epoch: 1, step: 623, loss: 0.64461, acc: 0.57812\n","epoch: 1, step: 779, loss: 0.62761, acc: 0.60096\n","epoch: 1, step: 935, loss: 0.63642, acc: 0.60697\n","epoch: 1, step: 1091, loss: 0.60984, acc: 0.62861\n","epoch: 1, step: 1247, loss: 0.62943, acc: 0.60216\n","epoch: 1, step: 1403, loss: 0.62357, acc: 0.61178\n","epoch: 1, step: 1559, loss: 0.62351, acc: 0.59495\n","Elapsed Time: 1:59:09.636990\n","======================== end training ========================\n"]}],"source":["optimizer = optim.Adam(model.parameters(), lr=1e-3)\r\n","criterion = nn.MultiLabelSoftMarginLoss()\r\n","\r\n","loss_list = []\r\n","acc_list = []\r\n","\r\n","num_epochs = 1\r\n","model.train()\r\n","start_time = datetime.now()\r\n","print('======================= start training =======================')\r\n","for epoch in range(num_epochs):\r\n","    for i, (images, targets) in enumerate(train_loader):\r\n","        optimizer.zero_grad()\r\n","\r\n","        images = images.to(device)\r\n","        targets = targets.to(device)\r\n","\r\n","        outputs = model(images).to(device)\r\n","        loss = criterion(outputs, targets)\r\n","\r\n","        loss.backward()\r\n","        optimizer.step()\r\n","\r\n","        if (i+1) % (int(0.1*len(train_loader))) == 0:\r\n","            outputs = outputs \u003e 0.5\r\n","            acc = (outputs == targets).float().mean()\r\n","            loss_list.append(loss)\r\n","            acc_list.append(acc)\r\n","            print(f'epoch: {epoch}, step: {i}, loss: {loss.item():.5f}, acc: {acc.item():.5f}')\r\n","\r\n","end_time = datetime.now()\r\n","print('\\nElapsed Time:', end_time - start_time)\r\n","print('======================== end training ========================')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jefM6gjWT0ki"},"outputs":[],"source":["plt.title('acc trend')\r\n","plt.xlabel('epochs')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"yj42gdsZH723"},"outputs":[],"source":["submit = pd.read_csv('./sample_submission.csv')\r\n","\r\n","model.eval()\r\n","batch_size = test_loader.batch_size\r\n","batch_index = 0\r\n","for i, (images, targets) in enumerate(test_loader):\r\n","    images = images.to(device)\r\n","    targets = targets.to(device)\r\n","    outputs = model(images).to(device)\r\n","    outputs = outputs \u003e 0.5\r\n","    batch_index = i * batch_size\r\n","    submit.iloc[batch_index:batch_index+batch_size, 1:] = \\\r\n","        outputs.long().squeeze(0).detach().cpu().numpy()\r\n","\r\n","submit.to_csv('./submit.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N2OXJJmxQ_cQ"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyML9fLewDoUmK0+IolU3ECW","collapsed_sections":[],"name":"dirty_mnist.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}